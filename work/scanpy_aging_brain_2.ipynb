{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:\n",
    "# Weighted covariance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datafetch\n",
    "# !wget ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE129nnn/GSE129788/suppl/GSE129788_RAW.tar\n",
    "# !tar -xvf GSE129788_RAW.tar\n",
    "# !gunzip *.gz\n",
    "\n",
    "# Accessions for raw datafetch:\n",
    "# accessions = [\n",
    "#     \"SRR8895023\",\n",
    "#     \"SRR8895024\",\n",
    "#     \"SRR8895025\",\n",
    "#     \"SRR8895026\",\n",
    "#     \"SRR8895027\",\n",
    "#     \"SRR8895028\",\n",
    "#     \"SRR8895029\",\n",
    "#     \"SRR8895030\",\n",
    "#     \"SRR8895031\",\n",
    "#     \"SRR8895032\",\n",
    "#     \"SRR8895033\",\n",
    "#     \"SRR8895034\",\n",
    "#     \"SRR8895035\",\n",
    "#     \"SRR8895036\",\n",
    "#     \"SRR8895037\",\n",
    "#     \"SRR8895038\",\n",
    "# ]\n",
    "\n",
    "\n",
    "# Assembly is mostly GCF_000001635.20, except for last which is MM10? \n",
    "# Don't use 16\n",
    "\n",
    "# age = [\n",
    "#     'old',\n",
    "#     'old',\n",
    "#     'old',\n",
    "#     'old',\n",
    "#     'old',\n",
    "#     'old',\n",
    "#     'old',\n",
    "#     'young',\n",
    "#     'young',\n",
    "#     'young',\n",
    "#     'young',\n",
    "#     'young',\n",
    "#     'young',\n",
    "#     'young',\n",
    "#     'young',\n",
    "#     'old', # weird assemblym mm10 for some reason?    \n",
    "# ]\n",
    "\n",
    "# Hooray for garbage that hasn't been maintained since the reagan administration\n",
    "\n",
    "# for acc in accessions:\n",
    "#     !./sratoolkit.2.10.8-ubuntu64/bin/prefetch {acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SRAs were moved to the folder \n",
    "\n",
    "# For shell background paralleleizaiton this will have to be a shell script:\n",
    "\n",
    "# for acc in $(find ./aging_brain/SRR*/*.sra)\n",
    "# do\n",
    "#         echo $acc\n",
    "#         echo $acc > $acc.log &\n",
    "#         ./sratoolkit.2.10.8-ubuntu64/bin/fastq-dump --readids --dumpbase --split-files --clip $acc > $acc.log 2>&1 &\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir aging_brain\n",
    "# !mv GSM37221* aging_brain\n",
    "# !mv GSE129788_RAW.tar aging_brain/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import scanpy as sc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_locations = !ls ./aging_brain/GSM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = []\n",
    "\n",
    "# for sample_location in sample_locations:\n",
    "#     samples.append(sc.read(sample_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = [s.T for s in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples are already normalized so we will have to stack them unless I want to spend forever and a day downloading bullshit raw data\n",
    "\n",
    "# samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = np.vstack([s.X for s in samples])\n",
    "# combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked = sc.AnnData(combined)\n",
    "# stacked.var_names = samples[0].var_names\n",
    "# stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_result = sc.pp.filter_genes_dispersion(  # select highly-variable genes\n",
    "#     stacked.X, flavor='cell_ranger', n_top_genes=2000, log=True\n",
    "# )\n",
    "# filtered = stacked[:, filter_result.gene_subset]     # subset the genes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to set up young vs old annotation:\n",
    "\n",
    "# young_mask = np.zeros(37069,dtype=bool)\n",
    "# old_mask = np.zeros(37069,dtype=bool)\n",
    "\n",
    "# young_samples = np.sum([s.shape[0] for s in samples[:8]])\n",
    "# young_mask[:young_samples] = True\n",
    "\n",
    "# old_samples = np.sum([s.shape[0] for s in samples[8:]])\n",
    "# old_mask[young_samples:] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_samples = stacked.shape[0]\n",
    "# batch_encoding = np.zeros((total_samples,len(samples)),dtype=bool)\n",
    "# batch_labels = np.zeros(total_samples)\n",
    "\n",
    "# for i,sample in enumerate(samples):\n",
    "#     current_total = np.sum(batch_encoding)\n",
    "#     batch_encoding[current_total:current_total+sample.shape[0],i] = True\n",
    "#     batch_labels[current_total:current_total+sample.shape[0]] = i\n",
    "    \n",
    "# np.savetxt(\"aging_batch_encoding.tsv\",batch_encoding,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# young_samples+old_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# young = filtered[young_mask].copy()\n",
    "# old = filtered[old_mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# pickle.dump(young,open(\"aging_brain_young.pickle\",mode='bw'))\n",
    "# pickle.dump(old,open(\"aging_brain_old.pickle\",mode='bw'))\n",
    "# pickle.dump(filtered,open(\"aging_brain_filtered.pickle\",mode='bw'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic scanpy processing:\n",
    "\n",
    "# sc.pp.neighbors(filtered)\n",
    "# sc.tl.umap(filtered)\n",
    "# sc.pl.umap(filtered)\n",
    "\n",
    "# sc.pp.neighbors(young)\n",
    "# sc.tl.umap(young)\n",
    "# sc.pl.umap(young)\n",
    "# sc.tl.louvain(young,resolution=3)\n",
    "# sc.pl.umap(young,color='louvain')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# r = np.arange(batch_encoding.shape[1])\n",
    "# batch_labels = np.array([r[m][0] for m in batch_encoding])\n",
    "\n",
    "# plt.figure(figsize=((10,10)))\n",
    "# plt.scatter(*filtered.obsm['X_umap'].T,s=1,c=batch_labels,cmap='rainbow')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure(figsize=((10,10)))\n",
    "# plt.scatter(*filtered.obsm['X_umap'].T,s=1,c=young_mask,alpha=.3,cmap='bwr')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# # sys.path.append('/localscratch/bbrener1/rusty_forest_v3/src')\n",
    "# sys.path.append('../src')\n",
    "# import tree_reader as tr \n",
    "# import lumberjack\n",
    "\n",
    "# forest = lumberjack.fit(\n",
    "#     young.X,\n",
    "# #     old.X,\n",
    "#     header=filtered.var_names,\n",
    "#     trees=300,\n",
    "#     braids=3,\n",
    "#     ifs=1000,\n",
    "#     ofs=1000,\n",
    "#     ss=500,\n",
    "#     depth=10,\n",
    "#     leaves=100,\n",
    "#     sfr=.5\n",
    "# )\n",
    "\n",
    "# forest.set_cache(True)\n",
    "# forest.backup(\"scanpy_cmp_aging_brain_trim_prediction\")\n",
    "\n",
    "# with open(\"scanpy_cmp_aging_brain_trim_prediction\", mode='bw') as f:\n",
    "#     pickle.dump(forest.old_predictions, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "\n",
    "import pickle \n",
    "\n",
    "young = pickle.load(open(\"aging_brain_young.pickle\",mode='rb'))\n",
    "old = pickle.load(open(\"aging_brain_old.pickle\",mode='rb'))\n",
    "filtered = pickle.load(open(\"aging_brain_filtered.pickle\",mode='rb'))\n",
    "\n",
    "batch_encoding = np.loadtxt('aging_batch_encoding.tsv')\n",
    "batch_encoding = batch_encoding.astype(dtype=bool)\n",
    "\n",
    "young_mask = np.zeros(37069,dtype=bool)\n",
    "old_mask = np.zeros(37069,dtype=bool)\n",
    "\n",
    "young_mask[:young.shape[0]] = True\n",
    "old_mask[young.shape[0]:] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/localscratch/bbrener1/rusty_forest_v3/src')\n",
    "sys.path.append('../src')\n",
    "import tree_reader as tr \n",
    "import lumberjack\n",
    "\n",
    "forest = tr.Forest.reconstitute('scanpy_cmp_aging_brain_trim_prediction')\n",
    "forest.arguments\n",
    "\n",
    "# old_forest = tr.Forest.reconstitute('scanpy_cmp_aging_brain_old')\n",
    "# old_forest.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we must interpret split clusters, since this will play a role in establishing the existence thereof\n",
    "# (I realize the paradox of creating a thing I have not proven exists, but hey, this isn't the philosophy department)\n",
    "\n",
    "# forest.reset_split_clusters()\n",
    "# forest.interpret_splits(depth=6,k=100,relatives=True,pca=100,mode='additive_mean',metric='cosine')\n",
    "# forest.interpret_splits(depth=8,k=100,relatives=True,pca=100,mode='additive_mean',metric='cosine')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we plot various feature representations of nodes. \n",
    "# This generates a set of figures demonstrating the existence of node clusters\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# sample_encoding = forest.node_representation(forest.nodes(depth=5),mode='sample')\n",
    "# reduced_sample = PCA(n_components=100).fit_transform(sample_encoding.T)\n",
    "# reduced_node = PCA(n_components=100).fit_transform(sample_encoding)\n",
    "\n",
    "# print(sample_encoding.shape)\n",
    "# print(reduced_sample.shape)\n",
    "# print(reduced_feature.shape)\n",
    "\n",
    "# from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "\n",
    "# sample_agglomeration = dendrogram(linkage(reduced_sample, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "# node_agglomeration = dendrogram(linkage(reduced_feature, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Figure 1: Sample Presence in Node (Two-Way Agglomerated)\")\n",
    "# plt.imshow(sample_encoding[node_agglomeration].T[sample_agglomeration].T,cmap='binary',interpolation='none')\n",
    "# plt.xlabel(\"Samples\")\n",
    "# plt.ylabel(\"Nodes\")\n",
    "# plt.colorbar()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# node_cluster_sort = np.argsort([n.split_cluster for n in forest.nodes(depth=5)])\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Figure S1: Sample Presence in Node (Clustered)\")\n",
    "# plt.imshow(sample_encoding[node_cluster_sort].T[sample_agglomeration].T,cmap='binary',interpolation='none')\n",
    "# plt.xlabel(\"Samples\")\n",
    "# plt.ylabel(\"Nodes\")\n",
    "# plt.colorbar()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# feature_encoding = forest.node_representation(forest.nodes(depth=5),mode='additive_mean')\n",
    "# reduced_feature = PCA(n_components=100).fit_transform(feature_encoding.T)\n",
    "# reduced_node = PCA(n_components=100).fit_transform(feature_encoding)\n",
    "\n",
    "# feature_agglomeration = dendrogram(linkage(reduced_feature, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Figure S2: Target Gain in Node (Clustered)\")\n",
    "plt.imshow(feature_encoding[node_cluster_sort].T[feature_agglomeration].T,cmap='bwr',interpolation='none',aspect='auto')\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Nodes\")\n",
    "plt.colorbar(label=\"Parent Target Mean - Node Target Mean\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = forest.split_cluster_transition_matrix()\n",
    "\n",
    "transition_agglomeration = dendrogram(linkage(transition_matrix.T, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Fig S3: Frequency of Transition Between Cluster Nodes\")\n",
    "plt.imshow(transition_matrix,cmap='binary')\n",
    "plt.ylabel(\"Origin\")\n",
    "plt.xlabel(\"Destination\")\n",
    "plt.colorbar(label=\"Number of transitions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we would like to demonstrate the existence of correlations that are unusual within the node clusters.\n",
    "\n",
    "global_correlations = forest.global_correlations()\n",
    "\n",
    "for cluster in forest.split_clusters:\n",
    "    print(\"#############################\")\n",
    "    print(cluster.id)\n",
    "    print(\"#############################\")\n",
    "\n",
    "    local_correlations = cluster.local_correlations()\n",
    "    most_local = cluster.most_local_correlations()\n",
    "    for (f1,f2) in most_local:\n",
    "        print((forest.output_features[f1],forest.output_features[f2]))\n",
    "        print(f\"Global:{global_correlations[f1,f2]}\")\n",
    "        print(f\"Local:{local_correlations[f1,f2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can demonstrate significant local behavior reversals. \n",
    "# Ex Apod vs Ptgds in cluster 17.\n",
    "# Global: .63 Pearson\n",
    "# Local: -.37 Pearson\n",
    "\n",
    "apod_index = list(forest.output_features).index(\"Apod\")\n",
    "ptgds_index = list(forest.output_features).index(\"Ptgds\")\n",
    "\n",
    "apod_values = forest.output[:,apod_index]\n",
    "ptgds_values = forest.output[:,ptgds_index]\n",
    "\n",
    "factor_17 = forest.factor_matrix()[:,17]\n",
    "mask_17 = np.abs(factor_17) > .1\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "global_slope,global_intercept,_,_,_ = linregress(apod_values,ptgds_values)\n",
    "local_slope,local_intercept,_,_,_ = linregress(apod_values[mask_17],ptgds_values[mask_17])\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Figure 4A: Apod vs. Ptgds Expression (Global)\")\n",
    "plt.scatter(apod_values,ptgds_values,s=1,alpha=.3,label=\"Raw Values\")\n",
    "plt.xlabel(\"Apod (Centered Log TPM)\")\n",
    "plt.ylabel(\"Ptgds (Centered Log TPM))\")\n",
    "plt.plot(np.arange(7), global_intercept + (np.arange(7) * global_slope),c='red',label=\"Linear Fit\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Figure 4B: Apod vs. Ptgds Expression (Factor 17 +/- Only)\")\n",
    "plt.scatter(apod_values[mask_17],ptgds_values[mask_17],s=1,alpha=.3,label=\"Raw Values\")\n",
    "plt.xlabel(\"Apod (Centered Log TPM)\")\n",
    "plt.ylabel(\"Ptgds (Centered Log TPM))\")\n",
    "plt.plot(np.arange(7), local_intercept + (np.arange(7) * local_slope),c='red',label=\"Linear Fit\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest.most_likely_tree(depth=6)\n",
    "forest.maximum_spanning_tree(mode='samples',depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forest.tsne_coordinates = young.obsm['X_umap']\n",
    "# forest.tsne()\n",
    "forest.html_tree_summary(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "forest.reset_sample_clusters()\n",
    "forest.cluster_samples_encoding(k=100,pca=100,depth=8,metric='cosine')\n",
    "# forest.cluster_samples_simple(pca=100,sub=.8,k=20,metric='cosine',verbose=True)\n",
    "forest.plot_sample_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = forest.factor_matrix()\n",
    "factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.cluster.hierarchy import dendrogram,linkage\n",
    "\n",
    "# factor_sort = np.array(dendrogram(linkage(np.abs(factors.T[1:]),metric='correlation',method='average'),no_plot=True)['leaves']) + 1 \n",
    "# sample_forest_sort = np.argsort(forest.sample_labels)\n",
    "# sample_agg_sort = dendrogram(linkage(np.abs(factors.T[1:].T),metric='cosine',method='average'),no_plot=True)['leaves']\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(factors[sample_forest_sort].T[factor_sort].T,aspect='auto',interpolation='none',cmap=\"seismic\",vmin=-1,vmax=1)\n",
    "# plt.colorbar()\n",
    "# plt.show()http://localhost:8888/notebooks/scanpy_aging_brain_2.ipynb#\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(factors[sample_agg_sort].T[factor_sort].T,aspect='auto',interpolation='none',cmap=\"seismic\",vmin=-1,vmax=1)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# young.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.sample_clusters[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model = PCA(n_components=22).fit(young.X)\n",
    "transformed = model.transform(young.X)\n",
    "recovered = model.inverse_transform(transformed)\n",
    "\n",
    "centered = young.X - np.mean(young.X,axis=0)\n",
    "transformed_residual = np.power(centered,2)\n",
    "\n",
    "recovered_residual = np.power(young.X - recovered,2)\n",
    "\n",
    "pca_recovered_per_sample = np.sum(recovered_residual,axis=1)\n",
    "pca_recovered_fraction_per_sample = np.sum(recovered_residual,axis=1) / np.sum(transformed_residual,axis=1)\n",
    "print(np.sum(transformed_residual))\n",
    "print(np.sum(recovered_residual))\n",
    "\n",
    "print(f\"Remaining variance:{(np.sum(recovered_residual) / np.sum(transformed_residual))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# forest.old_predictions = forest.predict(old.X)\n",
    "# forest.young_predicitons = forest.predict(young.X)\n",
    "# forest.young_predicitons.node_sample_encoding()\n",
    "# forest.old_predictions.node_sample_encoding()\n",
    "\n",
    "# entropy = forest.young_predicitons.compare_factors(forest.old_predictions)\n",
    "# entropy_sort = np.argsort(entropy)\n",
    "# print(list(zip(entropy_sort,np.array(entropy)[entropy_sort])))\n",
    "\n",
    "# old_residuals = np.power(old.X - np.mean(old.X,axis=0),2)\n",
    "# np.arange(2000)[np.sum(old_residuals,axis=0) <= 0]\n",
    "\n",
    "# forest.output_features[471]\n",
    "\n",
    "# old_features,old_samples = forest.old_predictions.prediction_report(mode='mean')\n",
    "# young_features,young_samples = forest.young_predicitons.prediction_report(mode='mean')\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(*young.obsm[\"X_umap\"].T,c=pca_recovered_fraction_per_sample,s=3,alpha=.4)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(*young.obsm[\"X_umap\"].T,c=young_samples,s=3,alpha=.4)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(*filtered.obsm[\"X_umap\"][young_mask].T,c=young_samples,s=3,alpha=.4)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(*filtered.obsm[\"X_umap\"][old_mask].T,c=old_samples,s=3,alpha=.4)\n",
    "# plt.colorbar()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(young_features,bins=np.arange(0,1,.05),log=True)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(old_features,bins=np.arange(0,1,.05),log=True)\n",
    "# plt.show()\n",
    "\n",
    "deltas,mismatch = forest.young_predicitons.compare_predictions(forest.old_predictions,bootstraps=1000,interval=.99999)\n",
    "\n",
    "\n",
    "# feature_index = list(forest.output_features).index(\"Snca\")\n",
    "\n",
    "# print(old_features[feature_index])\n",
    "# print(young_features[feature_index])\n",
    "\n",
    "# delta_sort = np.argsort(deltas)\n",
    "\n",
    "# print(list(delta_sort).index(feature_index))\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(deltas,bins=np.arange(0,1,.02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# young_mse = forest.young_predicitons.feature_mse()\n",
    "# old_mse = forest.old_predictions.feature_mse()\n",
    "# mse_jackknife = forest.young_predicitons.jackknife_feature_mse_variance()\n",
    "\n",
    "# jackknife_sort = np.argsort(mse_jackknife)\n",
    "# top_jackknife = jackknife_sort[-100:]\n",
    "delta_sort = np.argsort(deltas)\n",
    "top_deltas = delta_sort[-100:]\n",
    "\n",
    "# np.sum(mismatch)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title(\"Figure 5: MSE Of Predictions in Young vs Old Samples\")\n",
    "# plt.scatter(np.log(young_mse),np.log(old_mse),s=1)\n",
    "plt.scatter(young_mse,old_mse,s=1)\n",
    "plt.xlabel(\"Young (MSE Log TPM Expression)\")\n",
    "plt.ylabel(\"Old (MSE Log TPM Expression)\")\n",
    "plt.plot([0,1],[0,1],c='red')\n",
    "for i in top_deltas:\n",
    "    var = np.sqrt(mse_jackknife[i])\n",
    "    segment = var/np.sqrt(2)\n",
    "    x,y = (young_mse[i],old_mse[i])\n",
    "    plt.plot([x+segment,x-segment],[y,y],linewidth=1)\n",
    "#     whisker_p,whisker_m = x+segment,x-segment\n",
    "#     plt.plot(np.log([whisker_p,whisker_m]),np.log([y,y]),linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_top = delta_sort[-100:]\n",
    "reverse_top = np.array(list(reversed(reverse_top)))\n",
    "top_deltas = forest.output_features[reverse_top]\n",
    "delta_mse = deltas[reverse_top]\n",
    "\n",
    "for f,d in zip(top_deltas,delta_mse):\n",
    "    print(f\"{f}: \\t{np.around(d,decimals=3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We observe large MSE delta for SNCA \n",
    "# Let's plot its behavior VS KLK6 in the relevant cluster (17)\n",
    "\n",
    "# First we need to predict which samples in the old set will fall in cluster 17\n",
    "young_factors = forest.factor_matrix()\n",
    "old_factors = forest.old_predictions.factor_matrix()\n",
    "\n",
    "mask_17 = np.abs(young_factors[:,17]) > .1\n",
    "mask_17_old = np.abs(old_factors[:,17]) > .1\n",
    "\n",
    "print(young_factors.shape)\n",
    "print(old_factors.shape)\n",
    "\n",
    "snca_index = list(forest.output_features).index(\"Snca\")\n",
    "klk6_index = list(forest.output_features).index(\"Klk6\")\n",
    "\n",
    "snca_values_young = forest.output[:,snca_index][mask_17]\n",
    "klk6_values_young = forest.output[:,klk6_index][mask_17]\n",
    "\n",
    "snca_values_old = old.X[:,snca_index][mask_17_old]\n",
    "klk6_values_old = old.X[:,klk6_index][mask_17_old]\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "young_slope,young_intercept,_,_,_ = linregress(klk6_values_young,snca_values_young)\n",
    "old_slope,old_intercept,_,_,_ = linregress(klk6_values_old,snca_values_old)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Figure 6A: Klk6 vs SNCA (Young)\")\n",
    "plt.scatter(klk6_values_young,snca_values_young,s=1,label=\"Raw Values\")\n",
    "plt.plot(np.arange(6),(np.arange(6)*young_slope)+young_intercept,c='red',label='Linear Fit')\n",
    "plt.xlabel(\"Klk6\")\n",
    "plt.ylabel(\"SNCA\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Figure 6B: Klk6 vs SNCA (Old)\")\n",
    "plt.scatter(klk6_values_old,snca_values_old,s=1,label=\"Raw Values\")\n",
    "plt.plot(np.arange(6),(np.arange(6)*old_slope)+old_intercept,c='red',label='Linear Fit')\n",
    "plt.xlabel(\"Klk6\")\n",
    "plt.ylabel(\"SNCA\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../gsea/src')\n",
    "\n",
    "from gsea import gsea,readgenesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background = [g.upper() for g in forest.input_features]\n",
    "background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_sets = readgenesets(\"../gsea/data/kegg_allpathways.txt\")\n",
    "extant = []\n",
    "not_found = []\n",
    "for g in background:\n",
    "    for k in kegg_sets:\n",
    "        if g in kegg_sets[k]:\n",
    "            extant.append(g)\n",
    "            break\n",
    "    if g not in extant:\n",
    "        not_found.append(g)\n",
    "print(len(extant))\n",
    "extant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from colorama import Fore, Back, Style \n",
    "\n",
    "for cluster in forest.split_clusters[1:]:\n",
    "    changed_vs_sister,fold_vs_sister = cluster.logistic_sister()\n",
    "    test_up = [g.upper() for g in changed_vs_sister[-50:]]\n",
    "#     test_down = [g.upper() for g in changed_vs_sister[:50]]\n",
    "    enrichment = gsea(test_up,background,\"../gsea/data/kegg_allpathways.txt\")\n",
    "    sorted_enrichment = [(e,enrichment[e]) for e in sorted(enrichment,key=lambda x: enrichment[x][5])]\n",
    "    sorted_enrichment = [(e,s) for (e,s) in sorted_enrichment if s[0] > 0]\n",
    "    sorted_enrichment = [(e,s) for (e,s) in sorted_enrichment if s[5] < .05]\n",
    "    print(\"#######################\")\n",
    "    print(f\"Cluster {cluster.id}\")\n",
    "    print(\"#######################\")\n",
    "    print(\"\\n\".join([str(Fore.RED + e) + str(Fore.BLACK + str(s)) for (e,s) in sorted_enrichment]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(*forest.tsne_coordinates.T,s=1,c=forest.output[:,1571])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(forest.output_features).index('Rps23')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(*young.obsm['X_umap'].T,s=1,c=forest.output[:,1571])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we train a leave-one-out forest\n",
    "\n",
    "cv_forest = lumberjack.fit(\n",
    "    young.X[:-2648],\n",
    "    header=filtered.var_names,\n",
    "    trees=300,\n",
    "    braids=3,\n",
    "    ifs=700,\n",
    "    ofs=700,\n",
    "    ss=200,\n",
    "    depth=7,\n",
    "    leaves=100,\n",
    "    sfr=.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_forest.set_cache(True)\n",
    "# cv_forest.backup(\"scanpy_aging_brain_cv_forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_forest = tr.Forest.reconstitute('scanpy_aging_brain_cv_forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_forest.reset_split_clusters()\n",
    "cv_forest.interpret_splits(sub=.8,k=100,pca=100,depth=6,mode='additive_mean',intercon=3,cycles=3,relatives=True)\n",
    "# print(len(cv_forest.split_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_prediction = cv_forest.predict_matrix(young.X[-2648:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "target = young.X[-2648:]\n",
    "\n",
    "model = PCA(n_components=10).fit(target)\n",
    "recovery = model.inverse_transform(model.transform(target))\n",
    "\n",
    "deviation = np.power(target - np.mean(target,axis=0),2)\n",
    "print(f\"Observed deviation {np.sum(deviation)}\")\n",
    "recovered_deviation = np.power(recovery - np.mean(recovery,axis=0),2)\n",
    "print(f\"Recovered deviation {np.sum(recovered_deviation)}\")\n",
    "recovery_error = np.power(target - recovery,2)\n",
    "print(f\"Recovery error {np.sum(recovery_error)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_error = np.power(young.X[-2648:] - cv_prediction,2)\n",
    "print(f\"Forest error:{np.sum(forest_error)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(cv_prediction,aspect='auto',interpolation='none')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.imshow(young.X[-2648:],aspect='auto',interpolation='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_encoding = cv_forest.predict_node_sample_encoding(young.X[-2648:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_forest.most_likely_tree(depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = young.X[-2648:]\n",
    "\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    for cluster in cv_forest.split_clusters[1:]:\n",
    "        parent_cluster = cluster.parent_cluster()\n",
    "        print(f\"Cluster {cluster.id}\")\n",
    "        print(f\"Parent: {parent_cluster.id}\")\n",
    "        reg,features = cluster.regression()\n",
    "        parent_weights = np.abs(old_factors[:,parent_cluster.id])\n",
    "        print(f\"Local Old:{Fore.RED}{reg.score(old.X.T[features].T,old.X,sample_weight=parent_weights)}\")\n",
    "        print(f\"Global Old:{Fore.BLUE}{reg.score(old.X.T[features].T,old.X)}\")    \n",
    "        parent_weights = np.abs(young_factors[:,parent_cluster.id])\n",
    "        print(f\"Local Young:{Fore.RED}{reg.score(young.X.T[features].T,young.X,sample_weight=parent_weights)}\")\n",
    "        print(f\"Global Young:{Fore.BLUE}{reg.score(young.X.T[features].T,young.X)}\")    \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.reset_sample_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Back, Style \n",
    "\n",
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    g_o = []\n",
    "    l_o = []\n",
    "    g_y = []\n",
    "    l_y = []\n",
    "    e_o = []\n",
    "    e_y = []\n",
    "    for cluster in forest.split_clusters[1:]:\n",
    "        parent_cluster = cluster.parent_cluster()\n",
    "        print(\"########################\")\n",
    "        print(f\"Cluster {cluster.id}\")\n",
    "        print(f\"Parent: {parent_cluster.id}\")\n",
    "        p_y,n_y,a_y = cluster.error_ratio()\n",
    "        e_y.append((p_y+n_y)/a_y)\n",
    "        p_o,n_o,a_o = cluster.error_ratio(sample_matrix=old.X,scores=old_factors[:,cluster.id])\n",
    "        e_o.append((p_o+n_o)/a_o)\n",
    "        ff,f_r,r_r = cluster.regression()\n",
    "#         weights = np.abs(old_factors[:,parent_cluster.id])\n",
    "        weights = np.abs(old_factors[:,cluster.id])\n",
    "#         old_intermediate = f_r.predict(old.X).reshape(-1, 1)\n",
    "        old_intermediate = old.X.T[ff].T\n",
    "        global_old = r_r.score(old_intermediate,old.X)\n",
    "        local_old = r_r.score(old_intermediate,old.X,sample_weight=weights)\n",
    "        g_o.append(global_old)\n",
    "        l_o.append(local_old)\n",
    "        print(f\"Global Old:{Fore.RED}{global_old}{Fore.BLACK}\")\n",
    "        print(f\"Local Old:{Fore.BLUE}{local_old}{Fore.BLACK}\")    \n",
    "#         weights = np.abs(young_factors[:,parent_cluster.id])\n",
    "        weights = np.abs(young_factors[:,cluster.id])\n",
    "#         young_intermediate = f_r.predict(young.X).reshape(-1, 1)\n",
    "        young_intermediate = young.X.T[ff].T\n",
    "        global_young = r_r.score(young_intermediate,young.X)\n",
    "        local_young = r_r.score(young_intermediate,young.X,sample_weight=weights)\n",
    "        g_y.append(global_young)\n",
    "        l_y.append(local_young)\n",
    "        print(f\"Global Young:{Fore.RED}{global_young}{Fore.BLACK}\")    \n",
    "        print(f\"Local Young:{Fore.BLUE}{local_young}{Fore.BLACK}\")\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "for cluster in forest.split_clusters:\n",
    "    young_scores = young_factors[:,cluster.id]\n",
    "    old_scores = old_factors[:,cluster.id]\n",
    "    young_hist = np.histogram(young_scores,bins=np.arange(-1,1,.1))[0] + 1\n",
    "    old_hist = np.histogram(old_scores,bins=np.arange(-1,1,.1))[0] + 1\n",
    "    young_prob = young_hist / np.sum(young_hist)\n",
    "    old_prob = old_hist / np.sum(old_hist)\n",
    "#     print(\"##############################\")\n",
    "    print(f\"{cluster.id} Entropy: {entropy(young_prob,qk=old_prob)}\")\n",
    "#     print(\"##############################\")\n",
    "#     print(young_prob)\n",
    "#     print(old_prob)\n",
    "#     print(\"##############################\")\n",
    "    plt.figure()\n",
    "    plt.axes([0,.5,1,.5])\n",
    "    plt.ylabel(\"Young Frequency\")\n",
    "    plt.title(str(cluster.id))\n",
    "    plt.hist(young_scores,bins=np.arange(-.5,.5,.05),alpha=.5,density=True,color='gold',label=\"Young\",log=True)\n",
    "    plt.legend()\n",
    "    plt.axes([0,0,1,.5])\n",
    "    plt.ylabel(\"Old Frequency\")\n",
    "    plt.xlabel(\"Factor Value\")\n",
    "    plt.hist(old_scores,bins=np.arange(-.5,.5,.05),alpha=.5,color='blue',density=True,label=\"Old\",log=True)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.maximum_spanning_tree(mode='samples',depth=10)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(forest.sample_labels,alpha=.5,density=True,label=\"Young\",bins=np.arange(len(forest.sample_clusters)+1))\n",
    "# plt.hist(old_predicted_clusters,alpha=.5,density=True,label=\"Old\",bins=np.arange(len(forest.sample_clusters)+1))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft,cf = forest.sample_clusters[11].logistic_features()\n",
    "print(ft)\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,10))\n",
    "plt.scatter(l_y,g_y)\n",
    "plt.plot([0,.5],[0,.5])\n",
    "plt.plot([0,.5],[0,-.5])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(l_y,l_o)\n",
    "plt.plot([0,.5],[0,.5])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(g_y,g_o)\n",
    "plt.plot([0,.5],[0,.5])\n",
    "plt.plot([0,-.5],[0,-.5])\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(1-np.array(e_y),1-np.array(e_o))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from colorama import Fore, Back, Style \n",
    "\n",
    "# import warnings\n",
    "\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "\n",
    "#     for cluster in forest.split_clusters[1:]:\n",
    "#         parent_cluster = cluster.parent_cluster()\n",
    "#         print(\"########################\")\n",
    "#         print(f\"Cluster {cluster.id}\")\n",
    "#         print(f\"Parent: {parent_cluster.id}\")\n",
    "#         reg,features = cluster.regression()\n",
    "#         parent_weights = np.abs(old_factors[:,parent_cluster.id])\n",
    "#         print(f\"Local Old:{Fore.RED}{reg.score(old.X.T[features].T,old.X,sample_weight=parent_weights)}{Fore.BLACK}\")\n",
    "#         print(f\"Global Old:{Fore.BLUE}{reg.score(old.X.T[features].T,old.X)}{Fore.BLACK}\")    \n",
    "#         parent_weights = np.abs(young_factors[:,parent_cluster.id])\n",
    "#         print(f\"Local Young:{Fore.RED}{reg.score(young.X.T[features].T,young.X,sample_weight=parent_weights)}{Fore.BLACK}\")\n",
    "#         print(f\"Global Young:{Fore.BLUE}{reg.score(young.X.T[features].T,young.X)}{Fore.BLACK}\")    \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature = \"Ttyh2\"\n",
    "# f_i = forest.truth_dictionary.feature_dictionary[feature]\n",
    "# plt.figure()\n",
    "# plt.title(f'{feature}')\n",
    "# plt.scatter(*forest.tsne_coordinates.T,c=forest.output[:,f_i],s=3,alpha=.4)\n",
    "# plt.show()\n",
    "\n",
    "feature = \"Pdgfra\"\n",
    "f_i = forest.truth_dictionary.feature_dictionary[feature]\n",
    "plt.figure()\n",
    "plt.title(f'{feature}')\n",
    "plt.scatter(*forest.tsne_coordinates.T,c=forest.output[:,f_i],s=3,alpha=.4)\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(*forest.tsne_coordinates.T,c=forest.sample_labels == 24,s=3,alpha=.4)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"Gh\"\n",
    "f_i = forest.truth_dictionary.feature_dictionary[feature]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'{feature}')\n",
    "plt.scatter(*young.obsm[\"X_umap\"].T,c=forest.output[:,f_i],s=3,alpha=.4)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'{feature}')\n",
    "plt.scatter(*old.obsm['X_umap'].T,c=old.X[:,f_i],s=3,alpha=.4)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = \"Spock3\"\n",
    "f_i = forest.truth_dictionary.feature_dictionary[feature]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'{feature}')\n",
    "plt.scatter(*forest.tsne_coordinates.T,c=forest.output[:,f_i],s=3,alpha=.4)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f'{feature}')\n",
    "plt.scatter(*old.obsm['X_umap'].T,c=old.X[:,f_i],s=3,alpha=.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klk6_index = forest.truth_dictionary.feature_dictionary['Klk6']\n",
    "klk6_correlations = np.corrcoef(forest.output.T)[klk6_index]\n",
    "klk_sort = np.argsort(np.abs(klk6_correlations))\n",
    "top_features = forest.output_features[klk_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_features[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oligo_mask = forest.split_clusters[7].sister_scores() > 0\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(*forest.tsne_coordinates.T,c=oligo_mask,s=3,alpha=.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oligo_selection = forest.output[oligo_mask]\n",
    "\n",
    "oligo_correlations = np.corrcoef(oligo_selection.T)[klk6_index]\n",
    "oligo_correlations[~np.isfinite(oligo_correlations)] = 0.00000000001\n",
    "oligo_sort = np.argsort(np.abs(oligo_correlations))\n",
    "oligo_features = forest.output_features[oligo_sort][-20:]\n",
    "print(oligo_features)\n",
    "print(oligo_correlations[oligo_sort][-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oligo_old_mask = old_factors[:,7] > 0\n",
    "\n",
    "oligo_old_correlations = np.corrcoef(old.X[oligo_old_mask].T)[klk6_index]\n",
    "oligo_old_correlations[~np.isfinite(oligo_old_correlations)] = 0.000000000001\n",
    "oligo_old_sort = np.argsort(np.abs(oligo_old_correlations))\n",
    "oligo_old_features = forest.output_features[oligo_old_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oligo_old_features[-20:])\n",
    "print(oligo_old_correlations[oligo_old_sort][-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_correlations = oligo_correlations[:1999] - oligo_old_correlations\n",
    "delta_correlations[~np.isfinite(delta_correlations)] = .0000000001\n",
    "delta_sort = np.argsort(np.abs(delta_correlations))\n",
    "delta_features = forest.output_features[delta_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(delta_features[-20:])\n",
    "print(delta_correlations[delta_sort][-20:])\n",
    "print(oligo_correlations[delta_sort][-20:])\n",
    "print(oligo_old_correlations[delta_sort][-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mask1 = oligo_mask\n",
    "mask2 = oligo_old_mask\n",
    "\n",
    "f1 = \"Opalin\"\n",
    "f2 = \"Klk6\"\n",
    "f1i = forest.truth_dictionary.feature_dictionary[f1]\n",
    "f2i = forest.truth_dictionary.feature_dictionary[f2]\n",
    "\n",
    "noise11 = np.random.random(young.X.shape[0])/3\n",
    "noise12 = np.random.random(young.X.shape[0])/3\n",
    "noise21 = np.random.random(old.X.shape[0])/3\n",
    "noise22 = np.random.random(old.X.shape[0])/3\n",
    "\n",
    "plt.figure()\n",
    "ax1 = plt.axes([0,0,.8,.8])\n",
    "plt.scatter((young.X[:,f1i]+noise11)[mask1],(young.X[:,f2i]+noise12)[mask1],alpha=.5,s=2)\n",
    "plt.plot()\n",
    "ax2 = plt.axes([.8,0,.2,.8])\n",
    "plt.hist((young.X[:,f2i]+noise11)[mask1],bins=20,orientation='horizontal')\n",
    "ax3 = plt.axes([0,.8,.8,.2])\n",
    "plt.hist((young.X[:,f1i]+noise12)[mask1],bins=20)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "ax1 = plt.axes([0,0,.8,.8])\n",
    "plt.scatter((young.X[:,f1i]+noise11),(young.X[:,f2i]+noise12),alpha=.5,s=2)\n",
    "plt.plot()\n",
    "ax2 = plt.axes([.8,0,.2,.8])\n",
    "plt.hist((young.X[:,f2i]+noise11),bins=20,orientation='horizontal')\n",
    "ax3 = plt.axes([0,.8,.8,.2])\n",
    "plt.hist((young.X[:,f1i]+noise12),bins=20)\n",
    "plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# ax1 = plt.axes([0,0,.8,.8])\n",
    "# plt.scatter((old.X[:,f1i]+noise21)[mask2],(old.X[:,f2i]+noise22)[mask2],alpha=.5,s=2)\n",
    "# ax2 = plt.axes([.8,0,.2,.8])\n",
    "# plt.hist((old.X[:,f2i]+noise21)[mask2],bins=20,orientation='horizontal')\n",
    "# ax3 = plt.axes([0,.8,.8,.2])\n",
    "# plt.hist((old.X[:,f1i]+noise22)[mask2],bins=20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://link.springer.com/article/10.1007/s10048-016-0478-0\n",
    "# Snca expression associated with amyloid-like inclusion bodies, proteostatic stress? \n",
    "# Klk6 association reverses from .09 young to -.08 old. Now inverse association locally? \n",
    "# Klk6 & Spock3 both protease involved\n",
    "\n",
    "# Tubb3 Microtubule assembly, guidance of axons, maintenance\n",
    "# Spock3 modulates metalloproteases (High correlation/significance?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prkj_mask = young_factors[:,1] > 0\n",
    "prkj_old_mask = old_factors[:,1] > 0\n",
    "\n",
    "ppia_index = forest.truth_dictionary.feature_dictionary[\"Pcp4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prkj_local = young.X[prkj_mask]\n",
    "prkj_old_local = old.X[prkj_old_mask]\n",
    "\n",
    "prkj_local_correlations = np.corrcoef(prkj_local.T)[ppia_index]\n",
    "prkj_local_correlations[~np.isfinite(prkj_local_correlations)] = 0.00000000001\n",
    "prkj_local_sort = np.argsort(np.abs(prkj_local_correlations))\n",
    "prkj_local_features = forest.output_features[prkj_local_sort][-20:]\n",
    "print(prkj_local_features)\n",
    "print(prkj_local_correlations[prkj_local_sort][-20:])\n",
    "\n",
    "prkj_old_local_correlations = np.corrcoef(prkj_old_local.T)[ppia_index]\n",
    "prkj_old_local_correlations[~np.isfinite(prkj_old_local_correlations)] = 0.00000000001\n",
    "prkj_old_local_sort = np.argsort(np.abs(prkj_old_local_correlations))\n",
    "prkj_old_local_features = forest.output_features[prkj_old_local_sort][-20:]\n",
    "print(prkj_old_local_features)\n",
    "print(prkj_old_local_correlations[prkj_old_local_sort][-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prkj_delta_correlations = prkj_local_correlations[:1999] - prkj_old_local_correlations\n",
    "prkj_delta_correlations[~np.isfinite(prkj_delta_correlations)] = .0000000001\n",
    "prkj_delta_sort = np.argsort(np.abs(prkj_delta_correlations))\n",
    "prkj_delta_features = forest.output_features[prkj_delta_sort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prkj_delta_features[-20:])\n",
    "print(prkj_delta_correlations[prkj_delta_sort][-20:])\n",
    "print(prkj_local_correlations[prkj_delta_sort][-20:])\n",
    "print(prkj_old_local_correlations[prkj_delta_sort][-20:])\n",
    "\n",
    "# Go enrichment of the deltas was not obviously helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prkj_local_correlations[snca_i])\n",
    "print(prkj_old_local_correlations[snca_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sgk1, Spock3, C4b, inflammation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_correlations = np.corrcoef(old_forest.output.T)\n",
    "# local_correlations = old_forest.local_correlations()\n",
    "global_correlations[~np.isfinite(global_correlations)] = 0.000000001\n",
    "local_correlations[~np.isfinite(local_correlations)] = 0.0000000001\n",
    "delta_correlations = local_correlations - global_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klk6_index = old_forest.truth_dictionary.feature_dictionary['Klk6']\n",
    "klk_global_sort = np.argsort(np.abs(global_correlations[klk6_index]))\n",
    "klk_local_sort = np.argsort(np.abs(local_correlations[klk6_index]))\n",
    "delta_sort = np.argsort(np.abs(delta_correlations[klk6_index]))\n",
    "\n",
    "\n",
    "\n",
    "# print(old_forest.output_features[klk_global_sort][-20:])\n",
    "print(\"############## LOCAL ###############\")\n",
    "print(old_forest.output_features[klk_local_sort][-20:])\n",
    "print(\"############## DELTA ###############\")\n",
    "print(old_forest.output_features[delta_sort][-20:])\n",
    "print(global_correlations[klk6_index][delta_sort][-20:])\n",
    "print(local_correlations[klk6_index][delta_sort][-20:])\n",
    "\n",
    "for l,g in zip(klk_local_sort[-20:],klk_global_sort[-20:]):\n",
    "    print(f\"{old_forest.output_features[l]}\\t{old_forest.output_features[g]}\")\n",
    "    \n",
    "\n",
    "# snca_index = forest.truth_dictionary.feature_dictionary['Snca']\n",
    "# snca_global_sort = global_correlations[snca_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_correlations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.sample_clusters[5].increased_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.scatter(*forest.tsne_coordinates.T,c=np.array(young.obs['louvain']).astype(dtype=int),cmap='rainbow',s=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "\n",
    "sk_model = RF(n_estimators=100,min_samples_split=10,verbose=4,n_jobs=10,max_samples=500).fit(young.X,young.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predicted = sk_model.predict(young.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_residual = np.power(young.X - sk_predicted,2)\n",
    "\n",
    "print(np.sum(transformed_residual))\n",
    "print(np.sum(sk_residual))\n",
    "\n",
    "print(f\"Remaining variance:{1-(np.sum(sk_residual) / np.sum(transformed_residual))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
